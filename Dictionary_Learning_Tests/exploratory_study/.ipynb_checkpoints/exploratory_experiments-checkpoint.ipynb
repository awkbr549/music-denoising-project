{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import math\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.feature_extraction.image import reconstruct_from_patches_2d\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal will be distorted by a white noise and crackle\n",
    "#wf is the white noise factor (0.005 is a good start)\n",
    "#cf is the crackle noise factor (1000)\n",
    "def distort(signal,wf,cf):\n",
    "    height, width = signal.shape\n",
    "    #add white noise\n",
    "    signal += wf * np.random.randn(height, width)\n",
    "    \n",
    "    #add crackle noise\n",
    "    if (cf != 0):\n",
    "        for s in range(0,height):\n",
    "            for c in range(0,width):\n",
    "                if (np.random.randint(1, cf) == 1):\n",
    "                    signal[s][c] = 2.0*np.random.random() - 1.0\n",
    "                \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(signal, noise):\n",
    "    #SNR is the ratio of signal and noise strength\n",
    "    samples = signal.shape[0]*signal.shape[1]\n",
    "    if signal.shape != noise.shape:\n",
    "        print('error, signal and noise should be same size')\n",
    "        return\n",
    "    \n",
    "    #strength of a signal we measure the mean square value of the signal\n",
    "    s_str = 0.0\n",
    "    r_signal = signal.ravel()\n",
    "    r_noise = noise.ravel()\n",
    "    for s in r_signal:\n",
    "        s_str += s*s\n",
    "    s_str = math.sqrt(s_str / samples)\n",
    "    n_str = 0.0\n",
    "    for n in r_noise:\n",
    "        n_str += n*n\n",
    "    n_str = math.sqrt(n_str / samples)\n",
    "    return math.pow((s_str / n_str),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need an element wise measure of the prediction \n",
    "#SSE provides a decent measure of the spread of errors\n",
    "def SSE(predicted, truth):\n",
    "    sse = 0\n",
    "    pred = predicted.ravel()\n",
    "    t = truth.ravel()\n",
    "    for i, p in enumerate(pred):\n",
    "        sse += math.pow((t[i] - p),2)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, samplerate = sf.read('audio_sources\\\\train\\solo_43-53.wav') \n",
    "test, s = sf.read('audio_sources\\\\test\\solo_195-205.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters\n",
    "#training sources are a range of lengths to evaluate data size \n",
    "#train sources length = test sources length\n",
    "#patch_size for training = patch_size for testing\n",
    "patch_sizes = [(100,1), (100,2), (500,1), (500,2), (1000,1), (1000,2)]\n",
    "n_atoms = [100, 500, 1000]\n",
    "batch_sizes = [3, 100, 1000]\n",
    "train_sources = ['solo_43-53.wav', #vocals only from original\n",
    "                 'guitar_42-52.wav', #accoustic guitar cover\n",
    "                 'piano_42-52.wav'#, #piano cover \n",
    "                 #'instruments', #instruments only from original\n",
    "                 #'full' #original\n",
    "                ]                 \n",
    "train_types = ['clean','white','white_crackle']\n",
    "\n",
    "#testing parameters\n",
    "test_sources = ['solo_195-205.wav',\n",
    "                'guitar_112-122.wav',\n",
    "                'piano_194-204.wav'#, \n",
    "                #'instruments',\n",
    "                #'full' \n",
    "               ]\n",
    "test_types = ['white', 'crackle','white_crackle']\n",
    "transform_algorithms = [\n",
    "    ('lasso_lars', {'transform_alpha': 0.001}),\n",
    "    ('lasso_lars', {'transform_alpha': 0.01}),\n",
    "    ('lasso_lars', {'transform_alpha': 0.1}),\n",
    "    ('lasso_lars', {'transform_alpha': 1}),\n",
    "    ('lars', {'transform_n_nonzero_coefs': 2}),\n",
    "    ('lars', {'transform_n_nonzero_coefs': 20}),\n",
    "    ('lars', {'transform_n_nonzero_coefs': 40}),\n",
    "    ('omp', {'transform_n_nonzero_coefs': 2}),\n",
    "    ('omp', {'transform_n_nonzero_coefs': 20}),\n",
    "    ('omp', {'transform_n_nonzero_coefs': 40})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Default data, ictionary, and tranformation parameters\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x1_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x1_100atoms_batchsize100.sav,100x1,1.47,170.84,240839\n",
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,100x2,1.29,193.02,400839\n",
      "solo_43-53_patch500x1_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch500x1_100atoms_batchsize100.sav,500x1,6.77,301.95,880841\n",
      "solo_43-53_patch500x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch500x2_100atoms_batchsize100.sav,500x2,6.01,361.74,1680841\n",
      "solo_43-53_patch1000x1_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch1000x1_100atoms_batchsize100.sav,1000x1,13.09,395.68,1680841\n",
      "solo_43-53_patch1000x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "learning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch1000x2_100atoms_batchsize100.sav,1000x2,12.21,551.46,3280841\n"
     ]
    }
   ],
   "source": [
    "#PATCH SIZE REXPERIMENTS\n",
    "#runtime of training and size of model on disk vs patch sizes\n",
    "\n",
    "with open('patch_size_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,patch_size,data_time,learn_time,size_disk\\n')\n",
    "for i, patch_size in enumerate(patch_sizes):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_source\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_source[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_source[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_source[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "        \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    t_data1 = time()\n",
    "    data = train.copy()\n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    t_data1 = time() - t_data1\n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('learning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\patch_size\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%.2f,%d' % (name,patch,t_data1,t_learn,size))\n",
    "    with open('patch_size_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%.2f,%d\\n' % (name,patch,t_data1,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x2_100atoms_batchsize3.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize3.sav,3,44.37,400839\n",
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,100,193.09,400839\n",
      "solo_43-53_patch100x2_100atoms_batchsize1000.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize1000.sav,1000,1559.11,400840\n"
     ]
    }
   ],
   "source": [
    "#BATCH SIZE EXPERIMENTS \n",
    "#runtime of training and size of model vs batch size\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "with open('batch_size_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,batch_size,learn_time,size_disk\\n')\n",
    "for i, batch_size in enumerate(batch_sizes):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_source\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_source[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_source[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_source[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "        \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    \n",
    "    data = train.copy()\n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    \n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('\\tlearning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\batch_size\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%d' % (name,batch_size,t_learn,size))\n",
    "    with open('batch_size_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%d\\n' % (name,batch_size,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,100,192.67,400839\n",
      "solo_43-53_patch100x2_500atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_500atoms_batchsize100.sav,100,470.67,3600844\n",
      "solo_43-53_patch100x2_1000atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_1000atoms_batchsize100.sav,100,1144.05,11200844\n"
     ]
    }
   ],
   "source": [
    "#N ATOMS EXPERIMENTS \n",
    "#runtime of training and size of model vs number of atoms\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "with open('n_atoms_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,n_atoms,learn_time,size_disk\\n')\n",
    "for i, n_atom in enumerate(n_atoms):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_source\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_source[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_source[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_source[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "        \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    \n",
    "    data = train.copy()\n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    \n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('\\tlearning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\n_atoms\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%d' % (name,n_atom,t_learn,size))\n",
    "    with open('n_atoms_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%d\\n' % (name,n_atom,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haven't ran these fully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,clean,196.29,400839\n",
      "solo_43-53_white_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_white_patch100x2_100atoms_batchsize100.sav,white,197.09,400839\n",
      "solo_43-53_whitecrackle_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_whitecrackle_patch100x2_100atoms_batchsize100.sav,white_crackle,197.16,400839\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TYPES EXPERIMENTS \n",
    "#runtime of training and size of model vs train types\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "with open('train_types_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,train_type,learn_time,size_disk\\n')\n",
    "for i, train_type in enumerate(train_types):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_source\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_source[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_source[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_source[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "    \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    \n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    \n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('\\tlearning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\train_types\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%d' % (name,train_type,t_learn,size))\n",
    "    with open('train_types_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%d\\n' % (name,train_type,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,solo_43-53.wav,194.55,400839\n",
      "guitar_42-52_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tguitar_42-52_patch100x2_100atoms_batchsize100.sav,guitar_42-52.wav,148.05,400839\n",
      "piano_42-52_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tpiano_42-52_patch100x2_100atoms_batchsize100.sav,piano_42-52.wav,257.25,400839\n"
     ]
    }
   ],
   "source": [
    "#TRAIN SOURCE EXPERIMENTS \n",
    "#runtime of training and size of model vs train types\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "with open('train_sources_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,train_source,learn_time,size_disk\\n')\n",
    "for i, train_source in enumerate(train_sources):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_source\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_source[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_source[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_source[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "    \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    \n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    \n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('\\tlearning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\train_sources\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%d' % (name,train_source,t_learn,size))\n",
    "    with open('train_sources_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%d\\n' % (name,train_source,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav,10,194.82,400839\n",
      "solo_40-60_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_40-60_patch100x2_100atoms_batchsize100.sav,20,222.61,400839\n",
      "solo_30-70_patch100x2_100atoms_batchsize100.sav\n",
      "\tpreprocessing training data\n",
      "\tfinished preprocessing data\n",
      "\tlearning dictionary\n",
      "\tfinished learning dictionary\n",
      "\tsolo_30-70_patch100x2_100atoms_batchsize100.sav,40,268.17,400839\n"
     ]
    }
   ],
   "source": [
    "#TRAIN DATA LENGTH EXPERIMENTS \n",
    "#runtime of training and size of model vs length of training audio\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "train_lengths = ['solo_43-53.wav','solo_40-60.wav','solo_30-70.wav']\n",
    "\n",
    "with open('train_lengths_dictionary_runtimes.txt', 'w') as f:\n",
    "    f.write('model_name,train_lengths,learn_time,size_disk\\n')\n",
    "for i, train_length in enumerate(train_lengths):\n",
    "    patch = str(patch_size[0])+'x'+str(patch_size[1])\n",
    "    path = 'audio_sources\\\\train\\\\' + train_length\n",
    "    \n",
    "    if train_type == 'clean':\n",
    "        name = train_length[:-4] + '_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "    elif train_type == 'white':\n",
    "        name = train_length[:-4] + '_white_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0.005,0)\n",
    "    elif train_type == 'white_crackle':\n",
    "        name = train_length[:-4] + '_whitecrackle_patch'+patch+'_'+str(n_atom)+'atoms_'+'batchsize'+str(batch_size)+'.sav'\n",
    "        data, samplerate = sf.read(path)\n",
    "        data = distort(data,0,1000)\n",
    "    \n",
    "    data_length = int(train_length[8:10]) - int(train_length[5:7])\n",
    "    \n",
    "    print(name)\n",
    "    print('\\tpreprocessing training data')\n",
    "    \n",
    "    data = extract_patches_2d(data,patch_size)\n",
    "    data = data.reshape(data.shape[0],-1)\n",
    "    data -= np.mean(data, axis=0)\n",
    "    data /= np.std(data,axis=0)\n",
    "    \n",
    "    print('\\tfinished preprocessing data')\n",
    "    \n",
    "    print('\\tlearning dictionary')\n",
    "    t_learn = time()\n",
    "    params = MiniBatchDictionaryLearning(n_components=n_atom,batch_size=batch_size,n_jobs=-1)\n",
    "    model = params.fit(data)\n",
    "    t_learn = time() - t_learn\n",
    "    print('\\tfinished learning dictionary')\n",
    "    \n",
    "    save = 'models\\\\train_lengths\\\\' + name\n",
    "    joblib.dump(model,save)\n",
    "    \n",
    "    size = os.path.getsize(save)\n",
    "    \n",
    "    print('\\t%s,%s,%.2f,%d' % (name,data_length,t_learn,size))\n",
    "    with open('train_lengths_dictionary_runtimes.txt', 'a') as f:\n",
    "        f.write('%s,%s,%.2f,%d\\n' % (name,data_length,t_learn,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL EXPERIMENTS\n",
    "#runtime of denoising, SNR before, SNR after, SSE before, SSE after vs model used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary solo_30-70_patch100x2_100atoms_batchsize100.sav\n",
      "\tTesting dictioary on solo_195-205.wav\n",
      "\tlearning the sparse code\n",
      "\tfinished learning sparse code\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-7c67b21e797a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m#f.write('model_name,train_length,test_length,denoise_time,snr_before,snr_after,sse_before,sse_after\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t%s,%s,%.2f,%.3f,%.3f,%.2f,%.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_learn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnr_before\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnr_after\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse_before\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_lengths_dictionary_runtimes.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s,%s,%.2f,%.3f,%.3f,%.2f,%.2f\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_learn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnr_before\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msnr_after\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse_before\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "#TRAIN LENGTHS DENOISING EXPERIMENTS\n",
    "#runtime of denoising, SNR before, SNR after, SSE before, SSE after vs model used\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "#try each dictionary from lengths 10,20,&40s training on all the test sizes\n",
    "len_sources = ['solo_195-205.wav','solo_190-210.wav','solo_180-220.wav']\n",
    "\n",
    "with open('train_lengths_dictionary_denoise.txt', 'w') as f:\n",
    "    f.write('model_name,train_lengths,test_length,denoise_time,snr_before,snr_after,sse_before,sse_after\\n')\n",
    "\n",
    "models = os.listdir('models\\\\train_lengths')\n",
    "models.remove('results') #only process the models, not the results directory\n",
    "\n",
    "for index,model in enumerate(models):    \n",
    "    print('Loading dictionary ' + model)\n",
    "    i = model.find('-')\n",
    "    #print(model[i-2:i+3])\n",
    "    train_len = int(model[i+1:i+3]) - int(model[i-2:i])\n",
    "    \n",
    "    rpath = 'models\\\\train_lengths\\\\results\\\\'\n",
    "    mpath = 'models\\\\train_lengths\\\\' + model\n",
    "    \n",
    "    #load the dictionary and set the parameters\n",
    "    dictionary = joblib.load(mpath)\n",
    "    V = dictionary.components_\n",
    "    dictionary.set_params(transform_algorithm=test_param[0][0],**test_param[0][1])\n",
    "    \n",
    "    for source in len_sources:\n",
    "        print('\\tTesting dictioary on ' + source)\n",
    "        path = 'audio_sources\\\\test\\\\' + source\n",
    "        \n",
    "        j = source.find('-')\n",
    "        #print(model[j-3:j+2])\n",
    "        test_len = int(model[j:j+2]) - int(model[j-3:j-1])\n",
    "        h = source.find('.')\n",
    "        fname = source[:-h]\n",
    "        \n",
    "        #preprocess test data\n",
    "        clean,samplerate = sf.read(path)\n",
    "        height,width = clean.shape\n",
    "        test = clean.copy()\n",
    "        test = distort(test,0.005,0)\n",
    "        d_file = rpath + 'distorted_' + fname + '.wav'\n",
    "        sf.write(d_file,test,samplerate) #write the distorted file for archiving\n",
    "        \n",
    "        noise = clean.copy()\n",
    "        noise = test - clean\n",
    "        \n",
    "        snr_before = SNR(clean,noise)\n",
    "        sse_before = SSE(test,clean)\n",
    "        \n",
    "        test = extract_patches_2d(test,patch_size)\n",
    "        test = test.reshape(test.shape[0],-1)\n",
    "        intercept = np.mean(test,axis=0)\n",
    "        test -= intercept\n",
    "        \n",
    "        print('\\tlearning the sparse code')\n",
    "        t_learn = time()\n",
    "        code = dictionary.transform(test)\n",
    "        denoised = np.dot(code, V)\n",
    "        t_learn = t_learn - time()\n",
    "        print('\\tfinished learning sparse code')\n",
    "        \n",
    "        #post process the denoised data\n",
    "        denoised += intercept\n",
    "        denoised = denoised.reshape(len(denoised),*patch_size)\n",
    "        denoised = reconstruct_from_patches_2d(denoised,(height,width))\n",
    "        r_file = rpath + 'restored_' + fname + '.wav'\n",
    "        sf.write(r_file,denoised,samplerate)\n",
    "        \n",
    "        resid_noise = clean.copy()\n",
    "        resid_noise = clean - denoised\n",
    "        \n",
    "        snr_after = SNR(clean,resid_noise)\n",
    "        sse_after = SSE(denoised,clean)\n",
    "        \n",
    "        #f.write('model_name,train_length,test_length,denoise_time,snr_before,snr_after,sse_before,sse_after\\n')\n",
    "        print('\\t%s,%d,%d,%.2f,%.3f,%.3f,%.2f,%.2f' % (model,train_len,test_len,t_learn,snr_before,snr_after,sse_before,sse_after))\n",
    "        with open('train_lengths_dictionary_runtimes.txt', 'a') as f:\n",
    "            f.write('%s,%d,%d,%.2f,%.3f,%.3f,%.2f,%.2f\\n' % (model,train_len,test_len,t_learn,snr_before,snr_after,sse_before,sse_after))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size\n",
      "\tsolo_43-53_patch1000x2_100atoms_batchsize100.sav\n",
      "\tsolo_43-53_patch1000x2_100atoms_batchsize3.sav\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize1000.sav\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize3.sav\n",
      "n_atoms\n",
      "\tsolo_43-53_patch100x2_1000atoms_batchsize100.sav\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tsolo_43-53_patch100x2_500atoms_batchsize100.sav\n",
      "patch_size\n",
      "patch size of train must equal test patch size\n",
      "\t(1000, 1) solo_43-53_patch1000x1_100atoms_batchsize100.sav\n",
      "\t(1000, 2) solo_43-53_patch1000x2_100atoms_batchsize100.sav\n",
      "\t(100, 1) solo_43-53_patch100x1_100atoms_batchsize100.sav\n",
      "\t(100, 2) solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\t(500, 1) solo_43-53_patch500x1_100atoms_batchsize100.sav\n",
      "\t(500, 2) solo_43-53_patch500x2_100atoms_batchsize100.sav\n",
      "train_lengths\n",
      "train length must equal test length\n",
      "\taudio_sources\\test\\solo_180-220.wav solo_30-70_patch100x2_100atoms_batchsize100.sav\n",
      "\taudio_sources\\test\\solo_190-210.wav solo_40-60_patch100x2_100atoms_batchsize100.sav\n",
      "\taudio_sources\\test\\solo_195-205.wav solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "train_sources\n",
      "train source must equal test source\n",
      "\taudio_sources\\test\\guitar_112-122.wav guitar_42-52_patch100x2_100atoms_batchsize100.sav\n",
      "\taudio_sources\\test\\piano_194-204.wav piano_42-52_patch100x2_100atoms_batchsize100.sav\n",
      "\taudio_sources\\test\\solo_195-205.wav solo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "train_types\n",
      "\tsolo_43-53_patch100x2_100atoms_batchsize100.sav\n",
      "\tsolo_43-53_whitecrackle_patch100x2_100atoms_batchsize100.sav\n",
      "\tsolo_43-53_white_patch100x2_100atoms_batchsize100.sav\n"
     ]
    }
   ],
   "source": [
    "#MODEL EXPERIMENTS\n",
    "#runtime of denoising, SNR before, SNR after, SSE before, SSE after vs model used \n",
    "\n",
    "\n",
    "#set default values\n",
    "train_type = 'clean'\n",
    "train_source = 'solo_43-53.wav'\n",
    "test_type = 'white'\n",
    "test_source = 'solo_195-205.wav'\n",
    "patch_size = (100,2)\n",
    "n_atom = 100\n",
    "batch_size = 100\n",
    "test_param = [('omp', {'transform_n_nonzero_coefs': 20})]\n",
    "\n",
    "#Loop through all the models\n",
    "for dirs in os.listdir('models'):\n",
    "    print(dirs)\n",
    "    d = 'models\\\\' + dirs\n",
    "    \n",
    "    #parse the directory and model name structure to ensure proper tests\n",
    "    #defaults are presumed if not testing a directory with a varying parameter\n",
    "    #length of training file should equal length of test file\n",
    "    if dirs == 'train_lengths':\n",
    "        print('train length must equal test length')\n",
    "        for model in os.listdir(d):\n",
    "            i = model.find('-')\n",
    "            if model[i-2:i+3] == '43-53':\n",
    "                test_source = 'audio_sources\\\\test\\\\solo_195-205.wav'\n",
    "            elif model[i-2:i+3] == '40-60':\n",
    "                test_source = 'audio_sources\\\\test\\\\solo_190-210.wav'\n",
    "            elif model[i-2:i+3] == '30-70':\n",
    "                test_source = 'audio_sources\\\\test\\\\solo_180-220.wav'\n",
    "            else:\n",
    "                print('error in train lengths')\n",
    "            print('\\t' + test_source + ' ' + model)\n",
    "            \n",
    "            #load the dictionary and set the parameters\n",
    "            dictionary = joblib.load(model)\n",
    "            V = dictionary.components_\n",
    "            \n",
    "            #preprocess test data\n",
    "            test,samplerate = sf.read(test_source)\n",
    "            test = distort(test,0.005,0)\n",
    "            d_time = time()\n",
    "            test = extract_patches_2d(test,patch_size)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    #source of training should equal source of test\n",
    "    elif dirs == 'train_sources':\n",
    "        print('train source must equal test source')\n",
    "        for model in os.listdir(d):\n",
    "            i = model.find('_') #delimits the source\n",
    "            if model[:i] == 'solo':\n",
    "                test_source = 'audio_sources\\\\test\\\\solo_195-205.wav'\n",
    "            elif model[:i] == 'piano':\n",
    "                test_source = 'audio_sources\\\\test\\\\piano_194-204.wav'\n",
    "            elif model[:i] == 'guitar':\n",
    "                test_source = 'audio_sources\\\\test\\\\guitar_112-122.wav'\n",
    "            else:\n",
    "                print('error in train sources')\n",
    "            print('\\t' + test_source + ' ' + model)\n",
    "    \n",
    "    #patch sizes must be equal in train and test\n",
    "    elif dirs == 'patch_size':\n",
    "        print('patch size of train must equal test patch size')\n",
    "        for model in os.listdir(d):\n",
    "            i = model.find('x') #shape is dimxdim in model name\n",
    "            if i == 19:\n",
    "                patch_size = (int(model[i-3:i]),int(model[i+1]))\n",
    "            elif i == 20:\n",
    "                patch_size = (int(model[i-4:i]),int(model[i+1]))\n",
    "            else:\n",
    "                print('error in patch_size')\n",
    "            print('\\t' + str(patch_size) + ' ' + model)\n",
    "    \n",
    "    #all other models use default test_source and patch_size\n",
    "    else:\n",
    "        for model in os.listdir(d):\n",
    "            print('\\t' + model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In analysis, parse model name to directly extract parameters for comparison\n",
    "#Alternatively, load the model and extract the parameters for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.set_params(transform_algorithm=test_param[0][0],**test_param[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('pre-processing test audio with white noise')\n",
    "    clean = test.copy()\n",
    "    dist = test.copy()\n",
    "    dist = distort(dist,0.005,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchDictionaryLearning(alpha=1, batch_size=3, dict_init=None,\n",
       "              fit_algorithm='cd', n_components=100, n_iter=1000, n_jobs=-1,\n",
       "              positive_code=False, positive_dict=False, random_state=None,\n",
       "              shuffle=True, split_sign=False, transform_algorithm='omp',\n",
       "              transform_alpha=None, transform_n_nonzero_coefs=20,\n",
       "              verbose=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(transform_algorithm=transform_algorithm[0][0],**transform_algorithm[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
